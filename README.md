# 常见问题解答
## 它能用于三人麻将牌谱检讨吗？
不能。三人麻将是一个完全不同的游戏。

## 引擎在麻将中的表现有多好？
我们并不清楚，因为我们没有一个良好的、一致的、有效的、正统的、可靠的手段来评估它在人类标准中的强度。

## 什么是“pt”
“pt”与天凤段位pt是一个概念。简言之，它们就是对局结束时最终排名的加权形式。“90, 45, 0, -135”是一位七段选手在天凤凤桌半庄战的pt分布。

## 它们之间相互进行自战比较结果如何？
在重复对战中，1家akochan对3家Mortal以“90, 45, 0, -135”的pt分布为标准来看，Mortal胜出akochan的平均段位在2.479，平均pt有2.482；在“90, 30, -30, -90”的pt分布下以平均段位2.482和平均pt 1.961胜出。

相关细节日后将在Mortal的文件中注明。

## (Mortal) 里面各种记号都是什么意思？
$P_k^p$ 是一个向量，由玩家 $p$ 所打出的局面的4个顺位的可能性组成, 在游戏中的一局 $k$ 开始时进行评估。

$\Phi_k$ 是pt期望，在游戏中的一局 $k$ 开始时进行估计。

$\hat Q^\pi(s_k^i, a_k^i)$ 是在第 $k$ 局第 $i$ 个状态以 $\pi$ 为模型方针代表而算得的[Q 值](https://en.wikipedia.org/wiki/Q-learning)。

Mortal的Q值优化目标是 $\Phi_{k+1} - \Phi_k$ ，
所以理论上 $\hat Q^\pi(s_k^i, a_k^i) + \Phi_k$ 就是对pt期望的一个估计。

## (Mortal) 为什么除了最佳行动以外，其他的行动有时会明显低于最佳Q值？
如上所述， $\hat Q^\pi(s_k^i, a_k^i) + \Phi_k$ 是对pt期望的一个估计。 然而，对于这个值的估计只是
**<ins>一种方法手段而不是目标</ins>**
。明确地来讲，Mortal作为一个麻将AI，其真正的基本目的是在麻将游戏中取得最好的成绩，而不是为所有行动计算出准确的分数。因此，除了最好的动作之外，其他所有的行动的估计值都有可能是不够准确的；它们仅仅是作为一种衡量其在训练中的搜索偏好的手段。

这是一个开发利用与探索研究之间的两难困境。首先，Mortal是[无模型]([https://en.wikipedia.org/wiki/Model-free_(强化学习)](https://en.wikipedia.org/wiki/Model-free_(reinforcement_learning)))的，这意味着它没办法获得优化的目标，即在不去实际估计行动 $a$ 的情况下的实际的Q值 $Q^\pi(s_k^i, a_k^i)$ 。
因此，如果我们打算使得行动的Q值更加精确，模型将不得不去更多地搜索那些不太可行的动作，这可能导致对于部分并不好的行动的估值偏高，因而会使得最终的表现变差。在像麻将这样的有很大随机性的游戏中，这种过高估计是常有可能发生的，因为其中的方差特别大。为了避免此类性能退化，模型需要利用到更多的内容，因此就会导致出现不那么准确的Q值预测值 $\hat Q^\pi(s_k^i, a_k^i)$ 。

## (akochan) 如何配置pt分布？
在“tactics.json”中，修改“jun_pt”的值。注意到4个顺位的pt范围都在-200~200之间。

## (akochan) 为什么akochan有时候的表现显得非常地诡异？
Akochan不擅长开杠判断，极端情况下还会有数值稳定性问题。

Akochan执著于它的“最终任务目标”——pt期望，而并非是仅仅拿下这一轮。

## 估计值是如何计算出来的？
$$
100 \times (
    \frac{1}{k} \displaystyle \sum_{k=1}^k
    \frac{1}{i} \displaystyle \sum_{i=1}^n
    \frac
    {\hat Q^\pi(s_k^i, a_k^i) - \displaystyle \min_a \hat Q^\pi(s_k^i, a_k^i)}
    {\displaystyle \max_a \hat Q^\pi(s_k^i, a_k^i) - \displaystyle \min_a \hat Q^\pi(s_k^i, a_k^i)}
) ^ 2
$$

这只是一个最简单的计算的方法，并不非常可靠。
